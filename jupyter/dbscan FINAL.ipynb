{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data visualisaton params for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 0.1\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '../datasets/staandelamp_realistic.json'\n",
    "df_data = pd.read_json(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the data on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>TEMP</font> Cut off the dataset (Grab around 6 hours of timestamps) <font color='red'>TEMP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1509489940655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Staande_Lamp_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1509490011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Staande_Lamp_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1509491943009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staande_Lamp_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1509492221471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1509492826941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  state           time\n",
       "2  Staande_Lamp_3      0  1509489940655\n",
       "6  Staande_Lamp_5      1  1509490011225\n",
       "0  Staande_Lamp_1      1  1509491943009\n",
       "1  Staande_Lamp_2      0  1509492221471\n",
       "3  Staande_Lamp_3      1  1509492826941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data[:42]\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_dataframe_for_fitting(df):\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    df_fit = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "    df_fit['time'] = df['time']\n",
    "    return df_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the DBSCAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_untill_its_a_cluster = 2\n",
    "\n",
    "def fit_model(df, eps_distance_in_milliseconds):\n",
    "    model = DBSCAN(\n",
    "        eps=eps_distance_in_milliseconds, \n",
    "        min_samples=min_samples_untill_its_a_cluster\n",
    "    ).fit(df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(model):\n",
    "    info_dict = {}\n",
    "    info_dict['amount_of_datapoints'] = model.labels_.size\n",
    "    info_dict['amount_of_outliers'] = Counter(model.labels_)[-1]\n",
    "    \n",
    "    \n",
    "    cluster_data_count = Counter(model.labels_)\n",
    "    cluster_data_count.pop(-1) # don't count outliers as a cluster\n",
    "    if (bool(cluster_data_count)):\n",
    "        amount_of_clusters = max(cluster_data_count) + 1\n",
    "    else:\n",
    "        amount_of_clusters = 0;\n",
    "    info_dict['amount_of_clusters'] = amount_of_clusters\n",
    "    info_dict['datapoints_per_cluster_dict'] = Counter(model.labels_)\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_on_cluster(model, df):\n",
    "    df['cluster'] = model.labels_\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    \n",
    "    amount_of_clusters = get_model_info(model)['amount_of_clusters']\n",
    "    \n",
    "    for idx in range(amount_of_clusters):\n",
    "        cluster_dict[idx] = df.loc[df['cluster'] == idx].drop(columns=['cluster'])\n",
    "\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_large_clusters(cluster_dict, limit_in_milliseconds):\n",
    "    too_large_clusters_dataframes_dict = {}\n",
    "\n",
    "    for idx, df in cluster_dict.items():\n",
    "\n",
    "        first_time = df['time'].iloc[0]\n",
    "        last_time = df['time'].iloc[df['time'].size - 1]\n",
    "\n",
    "        diffrence_in_miliseconds = last_time - first_time\n",
    "        # diffrence_in_minutes = diffrence_in_miliseconds / 1000 / 60\n",
    "\n",
    "        if diffrence_in_miliseconds > limit_in_milliseconds:\n",
    "            too_large_clusters_dataframes_dict[idx] = df\n",
    "\n",
    "    return too_large_clusters_dataframes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (300000 milliseconds = 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def do_shit(df, eps, iteration=0):\n",
    "    \n",
    "    indentation = '';\n",
    "    for x in range(iteration):\n",
    "        indentation += '    '\n",
    "    indentation += '|--'\n",
    "    \n",
    "    model = fit_model(df, eps)\n",
    "    cluster_dict = split_dataframe_on_cluster(model, df)\n",
    "    too_large_clusters_dict = get_too_large_clusters(cluster_dict, eps)\n",
    "    \n",
    "    \n",
    "    # print('MODEL INFO')\n",
    "    # pp.pprint(get_model_info(model))\n",
    "    # print('\\n')\n",
    "    \n",
    "    if (len(too_large_clusters_dict) > 0):\n",
    "        print(indentation, len(too_large_clusters_dict), 'cluster(s) is/are too large with an EPS of ', eps, '\\n')\n",
    "    else:\n",
    "        print(indentation, 'no clusters are too large :) :) with an EPS of ', eps, '\\n')\n",
    "\n",
    "    for idx, df in too_large_clusters_dict.items():\n",
    "        if eps == 300000:\n",
    "            print(indentation, 'CLUSTER WITH ID', idx, 'is too large')\n",
    "            \n",
    "        print(indentation, 'RUNNING IT AGAIN with an EPS of ', eps / 2)\n",
    "        do_shit(too_large_clusters_dict[idx], eps / 2, iteration + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering bulshit...\n",
      "|-- 2 cluster(s) is/are too large with an EPS of  300000 \n",
      "\n",
      "|-- CLUSTER WITH ID 6 is too large\n",
      "|-- RUNNING IT AGAIN with an EPS of  150000.0\n",
      "    |-- no clusters are too large :) :) with an EPS of  150000.0 \n",
      "\n",
      "|-- CLUSTER WITH ID 10 is too large\n",
      "|-- RUNNING IT AGAIN with an EPS of  150000.0\n",
      "    |-- 1 cluster(s) is/are too large with an EPS of  150000.0 \n",
      "\n",
      "    |-- RUNNING IT AGAIN with an EPS of  75000.0\n",
      "        |-- no clusters are too large :) :) with an EPS of  75000.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "five_minutes = 300000\n",
    "df_fit = clean_dataframe_for_fitting(df_data)\n",
    "\n",
    "print('clustering bulshit...')\n",
    "do_shit(df_fit, five_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected clusters 7 (id=6) and cluster 11 (id=10) to be too large with an EPS of 30000 (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../datasets/images/expected_6_hours_realistic_legend.png)\n",
    "![title](../datasets/images/expected_6_hours_realistic_sub_clustering.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
