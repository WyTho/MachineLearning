{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data visualisaton params for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 0.1\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '../datasets/staandelamp_realistic.json'\n",
    "df_data = pd.read_json(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the data on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>TEMP</font> Cut off the dataset (Grab around 6 hours of timestamps) <font color='red'>TEMP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1509489940655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Staande_Lamp_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1509490011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Staande_Lamp_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1509491943009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staande_Lamp_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1509492221471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1509492826941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  state           time\n",
       "2  Staande_Lamp_3      0  1509489940655\n",
       "6  Staande_Lamp_5      1  1509490011225\n",
       "0  Staande_Lamp_1      1  1509491943009\n",
       "1  Staande_Lamp_2      0  1509492221471\n",
       "3  Staande_Lamp_3      1  1509492826941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_dataframe_for_fitting(df):\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    df_fit = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "    df_fit['state'] = df['state']\n",
    "    df_fit['time'] = df['time']\n",
    "    return df_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the DBSCAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_untill_its_a_cluster = 2\n",
    "\n",
    "def fit_model(df, eps_distance_in_milliseconds):\n",
    "    model = DBSCAN(\n",
    "        eps=eps_distance_in_milliseconds, \n",
    "        min_samples=min_samples_untill_its_a_cluster\n",
    "    ).fit(df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(model):\n",
    "    info_dict = {}\n",
    "    info_dict['amount_of_datapoints'] = model.labels_.size\n",
    "    info_dict['amount_of_outliers'] = Counter(model.labels_)[-1]\n",
    "    \n",
    "    \n",
    "    cluster_data_count = Counter(model.labels_)\n",
    "    if -1 in cluster_data_count:\n",
    "        cluster_data_count.pop(-1) # don't count outliers as a cluster\n",
    "    if (bool(cluster_data_count)):\n",
    "        amount_of_clusters = max(cluster_data_count) + 1\n",
    "    else:\n",
    "        amount_of_clusters = 0;\n",
    "    info_dict['amount_of_clusters'] = amount_of_clusters\n",
    "    info_dict['datapoints_per_cluster_dict'] = Counter(model.labels_)\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_on_cluster(model, df):\n",
    "    df['cluster'] = model.labels_\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    \n",
    "    amount_of_clusters = get_model_info(model)['amount_of_clusters']\n",
    "    \n",
    "    for idx in range(amount_of_clusters):\n",
    "        cluster_dict[idx] = df.loc[df['cluster'] == idx].drop(columns=['cluster'])\n",
    "\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_large_clusters(cluster_dict, limit_in_milliseconds):\n",
    "    too_large_clusters_dataframes_dict = {}\n",
    "\n",
    "    for idx, df in cluster_dict.items():\n",
    "\n",
    "        first_time = df['time'].iloc[0]\n",
    "        last_time = df['time'].iloc[df['time'].size - 1]\n",
    "\n",
    "        diffrence_in_miliseconds = last_time - first_time\n",
    "        # diffrence_in_minutes = diffrence_in_miliseconds / 1000 / 60\n",
    "\n",
    "        if diffrence_in_miliseconds > limit_in_milliseconds:\n",
    "            too_large_clusters_dataframes_dict[idx] = df\n",
    "\n",
    "    return too_large_clusters_dataframes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perfect_size_clusters(cluster_dict, limit_in_milliseconds):\n",
    "    perfect_size_clusters_dataframes_dict = {}\n",
    "\n",
    "    for idx, df in cluster_dict.items():\n",
    "\n",
    "        first_time = df['time'].iloc[0]\n",
    "        last_time = df['time'].iloc[df['time'].size - 1]\n",
    "\n",
    "        diffrence_in_miliseconds = last_time - first_time\n",
    "        # diffrence_in_minutes = diffrence_in_miliseconds / 1000 / 60\n",
    "\n",
    "        if diffrence_in_miliseconds <= limit_in_milliseconds:\n",
    "            perfect_size_clusters_dataframes_dict[idx] = df\n",
    "\n",
    "    return perfect_size_clusters_dataframes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (300000 milliseconds = 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "852\n",
      "1268\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def do_shit(df, eps, iteration=0, cluster_arr=[]):\n",
    "    \n",
    "    model = fit_model(df, eps)\n",
    "    cluster_dict = split_dataframe_on_cluster(model, df)\n",
    "    \n",
    "    too_large_clusters_dict = get_too_large_clusters(cluster_dict, eps * 1.5)\n",
    "    perfect_size_clusters = get_perfect_size_clusters(cluster_dict, eps * 1.5)\n",
    "    \n",
    "    for idx, df in too_large_clusters_dict.items():\n",
    "        cluster_arr + do_shit(too_large_clusters_dict[idx], eps / 2, iteration + 1, cluster_arr)\n",
    "    \n",
    "    for idx, df in perfect_size_clusters.items():\n",
    "        cluster_arr.append(df)\n",
    "    \n",
    "    return cluster_arr\n",
    "\n",
    "\n",
    "\n",
    "five_minutes = 300000\n",
    "\n",
    "one_week_in_milliseconds = (1000 * 60 * 60 * 24 * 7)\n",
    "last_timestamp = df_data['time'].max()\n",
    "\n",
    "weeks_clusters = []\n",
    "for week in range(3):\n",
    "    df_week_x = df_data[df_data['time'] >= last_timestamp - ((week + 1) * one_week_in_milliseconds)]\n",
    "    df_week_x = df_week_x[df_week_x['time'] < last_timestamp - (week * one_week_in_milliseconds)]\n",
    "    df_fit_1 = clean_dataframe_for_fitting(df_week_x.loc[df_week_x['state'] == 1])\n",
    "    df_fit_0 = clean_dataframe_for_fitting(df_week_x.loc[df_week_x['state'] == 0])\n",
    "    cluster_arr1 = do_shit(df_fit_1, five_minutes)\n",
    "    cluster_arr2 = do_shit(df_fit_0, five_minutes)\n",
    "    cluster_arr = cluster_arr1 + cluster_arr2\n",
    "    weeks_clusters.append(cluster_arr)\n",
    "\n",
    "\n",
    "print(len(weeks_clusters[0]))\n",
    "print(len(weeks_clusters[1]))\n",
    "print(len(weeks_clusters[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "746\n",
      "1102\n",
      "[[20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20], [20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 17, 9, 5, 21, 5, 18, 20, 3, 17, 12, 6, 5, 9, 20, 6, 5, 26, 6, 14, 5, 5, 20, 5, 20, 3, 6, 6, 24, 5, 28, 5, 7, 18, 20, 10, 20, 12, 6, 19, 17, 6, 12, 20, 9, 20, 5, 12, 6, 24, 20, 20, 5, 21, 13, 5, 5, 18, 5, 20, 5, 12, 21, 20, 12, 17, 6, 20, 9, 9, 14, 12, 10, 20, 18, 6, 3, 20, 20, 6, 12, 9, 5, 20, 9, 12, 3, 7, 18, 20, 24, 28, 3, 3, 28, 28, 14, 20, 5, 6, 20, 22, 17, 21, 17, 10, 20, 20, 13, 12, 21, 3, 9, 20, 6, 20, 5, 21, 17, 5, 12, 14, 25, 12, 5, 3, 20, 20, 14, 19, 9, 17, 5, 10, 13, 5, 24, 5, 3, 20, 6, 5, 9, 5, 18, 10, 21, 20, 5, 6, 6, 20, 6, 5, 6, 22, 6, 24, 6, 20, 10, 3, 12, 6, 5, 5, 9, 20, 10, 6, 12, 9, 6, 6, 6, 5, 12, 24, 6, 24, 20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 17, 9, 5, 21, 5, 18, 20, 3, 17, 12, 6, 5, 9, 20, 6, 5, 26, 6, 14, 5, 5, 20, 5, 20, 3, 6, 6, 24, 5, 28, 5, 7, 18, 20, 10, 20, 12, 6, 19, 17, 6, 12, 20, 9, 20, 5, 12, 6, 24, 20, 20, 5, 21, 13, 5, 5, 18, 5, 20, 5, 12, 21, 20, 12, 17, 6, 20, 9, 9, 14, 12, 10, 20, 18, 6, 3, 20, 20, 6, 12, 9, 5, 20, 9, 12, 3, 7, 18, 20, 24, 28, 3, 3, 28, 28, 14, 20, 5, 6, 20, 22, 17, 21, 17, 10, 20, 20, 13, 12, 21, 3, 9, 20, 6, 20, 5, 21, 17, 5, 12, 14, 25, 12, 5, 3, 20, 20, 14, 19, 9, 17, 5, 10, 13, 5, 24, 5, 3, 20, 6, 5, 9, 5, 18, 10, 21, 20, 5, 6, 6, 20, 6, 5, 6, 22, 6, 24, 6, 20, 10, 3, 12, 6, 5, 5, 9, 20, 10, 6, 12, 9, 6, 6, 6, 5, 12, 24, 6, 24], [20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 17, 9, 5, 21, 5, 18, 20, 3, 17, 12, 6, 5, 9, 20, 6, 5, 26, 6, 14, 5, 5, 20, 5, 20, 3, 6, 6, 24, 5, 28, 5, 7, 18, 20, 10, 20, 12, 6, 19, 17, 6, 12, 20, 9, 20, 5, 12, 6, 24, 20, 20, 5, 21, 13, 5, 5, 18, 5, 20, 5, 12, 21, 20, 12, 17, 6, 20, 9, 9, 14, 12, 10, 20, 18, 6, 3, 20, 20, 6, 12, 9, 5, 20, 9, 12, 3, 7, 18, 20, 24, 28, 3, 3, 28, 28, 14, 20, 5, 6, 20, 22, 17, 21, 17, 10, 20, 20, 13, 12, 21, 3, 9, 20, 6, 20, 5, 21, 17, 5, 12, 14, 25, 12, 5, 3, 20, 20, 14, 19, 9, 17, 5, 10, 13, 5, 24, 5, 3, 20, 6, 5, 9, 5, 18, 10, 21, 20, 5, 6, 6, 20, 6, 5, 6, 22, 6, 24, 6, 20, 10, 3, 12, 6, 5, 5, 9, 20, 10, 6, 12, 9, 6, 6, 6, 5, 12, 24, 6, 24, 20, 12, 22, 12, 20, 12, 17, 18, 7, 3, 20, 12, 24, 6, 5, 20, 20, 14, 6, 12, 24, 6, 18, 24, 20, 10, 17, 12, 6, 5, 24, 5, 20, 6, 5, 17, 9, 22, 9, 13, 9, 10, 28, 5, 6, 5, 12, 20, 10, 21, 14, 12, 5, 6, 28, 13, 12, 5, 12, 28, 5, 10, 22, 5, 10, 17, 20, 5, 24, 6, 10, 3, 5, 6, 20, 20, 9, 5, 6, 5, 10, 13, 20, 12, 12, 12, 18, 20, 12, 24, 20, 5, 15, 12, 20, 3, 12, 12, 25, 10, 5, 12, 18, 24, 5, 22, 12, 6, 13, 3, 9, 17, 20, 20, 12, 17, 20, 5, 20, 5, 9, 6, 12, 20, 9, 5, 6, 12, 3, 12, 20, 9, 12, 12, 12, 5, 19, 12, 3, 12, 5, 13, 5, 6, 9, 10, 12, 24, 6, 18, 17, 10, 6, 20, 20, 12, 18, 20, 9, 20, 9, 17, 28, 6, 12, 6, 13, 22, 20, 11, 20, 25, 9, 24, 9, 5, 14, 7, 20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 17, 9, 5, 21, 5, 18, 20, 3, 17, 12, 6, 5, 9, 20, 6, 5, 26, 6, 14, 5, 5, 20, 5, 20, 3, 6, 6, 24, 5, 28, 5, 7, 18, 20, 10, 20, 12, 6, 19, 17, 6, 12, 20, 9, 20, 5, 12, 6, 24, 20, 20, 5, 21, 13, 5, 5, 18, 5, 20, 5, 12, 21, 20, 12, 17, 6, 20, 9, 9, 14, 12, 10, 20, 18, 6, 3, 20, 20, 6, 12, 9, 5, 20, 9, 12, 3, 7, 18, 20, 24, 28, 3, 3, 28, 28, 14, 20, 5, 6, 20, 22, 17, 21, 17, 10, 20, 20, 13, 12, 21, 3, 9, 20, 6, 20, 5, 21, 17, 5, 12, 14, 25, 12, 5, 3, 20, 20, 14, 19, 9, 17, 5, 10, 13, 5, 24, 5, 3, 20, 6, 5, 9, 5, 18, 10, 21, 20, 5, 6, 6, 20, 6, 5, 6, 22, 6, 24, 6, 20, 10, 3, 12, 6, 5, 5, 9, 20, 10, 6, 12, 9, 6, 6, 6, 5, 12, 24, 6, 24, 20, 12, 22, 12, 20, 12, 17, 18, 7, 3, 20, 12, 24, 6, 5, 20, 20, 14, 6, 12, 24, 6, 18, 24, 20, 10, 17, 12, 6, 5, 24, 5, 20, 6, 5, 17, 9, 22, 9, 13, 9, 10, 28, 5, 6, 5, 12, 20, 10, 21, 14, 12, 5, 6, 28, 13, 12, 5, 12, 28, 5, 10, 22, 5, 10, 17, 20, 5, 24, 6, 10, 3, 5, 6, 20, 20, 9, 5, 6, 5, 10, 13, 20, 12, 12, 12, 18, 20, 12, 24, 20, 5, 15, 12, 20, 3, 12, 12, 25, 10, 5, 12, 18, 24, 5, 22, 12, 6, 13, 3, 9, 17, 20, 20, 12, 17, 20, 5, 20, 5, 9, 6, 12, 20, 9, 5, 6, 12, 3, 12, 20, 9, 12, 12, 12, 5, 19, 12, 3, 12, 5, 13, 5, 6, 9, 10, 12, 24, 6, 18, 17, 10, 6, 20, 20, 12, 18, 20, 9, 20, 9, 17, 28, 6, 12, 6, 13, 22, 20, 11, 20, 25, 9, 24, 9, 5, 14, 7]]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "week_hashcodes = []\n",
    "# hashcodes_3_weeks = []\n",
    "# hashcodes_last_week = []\n",
    "for week, cluster_arr in enumerate(weeks_clusters):\n",
    "    week_hashcodes.append([])\n",
    "    for idx, df in enumerate(cluster_arr):\n",
    "        cluster = []\n",
    "        for row in df.iterrows():\n",
    "            index, data = row\n",
    "            cluster.append(data['name'].tolist())\n",
    "\n",
    "        cluster = list(set(cluster))\n",
    "\n",
    "        hashcodedingus = 0\n",
    "        for lamp in cluster:\n",
    "            hashcodedingus += pow(2, lamp)\n",
    "\n",
    "        if(len(cluster) > 1):\n",
    "            week_hashcodes[week].append(hashcodedingus)\n",
    "            # hashcodes_3_weeks.append(hashcodedingus)\n",
    "            # if week == 0:\n",
    "            #     hashcodes_last_week.append(hashcodedingus)\n",
    "    \n",
    "print(len(week_hashcodes[0]))\n",
    "print(len(week_hashcodes[1]))\n",
    "print(len(week_hashcodes[2]))\n",
    "print(week_hashcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: {'occurance_week_0': 68,\n",
       "  'occurance_week_1': 130,\n",
       "  'occurance_week_2': 184},\n",
       " 17: {'occurance_week_0': 20, 'occurance_week_1': 36, 'occurance_week_2': 52},\n",
       " 5: {'occurance_week_0': 62, 'occurance_week_1': 122, 'occurance_week_2': 170},\n",
       " 25: {'occurance_week_0': 4, 'occurance_week_1': 6, 'occurance_week_2': 10},\n",
       " 6: {'occurance_week_0': 66, 'occurance_week_1': 118, 'occurance_week_2': 154},\n",
       " 18: {'occurance_week_0': 12, 'occurance_week_1': 24, 'occurance_week_2': 36},\n",
       " 12: {'occurance_week_0': 54, 'occurance_week_1': 84, 'occurance_week_2': 146},\n",
       " 10: {'occurance_week_0': 22, 'occurance_week_1': 36, 'occurance_week_2': 56},\n",
       " 24: {'occurance_week_0': 14, 'occurance_week_1': 28, 'occurance_week_2': 46},\n",
       " 14: {'occurance_week_0': 2, 'occurance_week_1': 12, 'occurance_week_2': 18},\n",
       " 22: {'occurance_week_0': 10, 'occurance_week_1': 14, 'occurance_week_2': 24},\n",
       " 9: {'occurance_week_0': 18, 'occurance_week_1': 42, 'occurance_week_2': 68},\n",
       " 21: {'occurance_week_0': 8, 'occurance_week_1': 22, 'occurance_week_2': 24},\n",
       " 13: {'occurance_week_0': 6, 'occurance_week_1': 12, 'occurance_week_2': 24},\n",
       " 3: {'occurance_week_0': 10, 'occurance_week_1': 30, 'occurance_week_2': 42},\n",
       " 7: {'occurance_week_0': 4, 'occurance_week_1': 8, 'occurance_week_2': 12},\n",
       " 26: {'occurance_week_0': 4, 'occurance_week_1': 6, 'occurance_week_2': 6},\n",
       " 28: {'occurance_week_0': 4, 'occurance_week_1': 12, 'occurance_week_2': 20},\n",
       " 19: {'occurance_week_0': 0, 'occurance_week_1': 4, 'occurance_week_2': 6},\n",
       " 15: {'occurance_week_0': 0, 'occurance_week_1': 0, 'occurance_week_2': 2},\n",
       " 11: {'occurance_week_0': 0, 'occurance_week_1': 0, 'occurance_week_2': 2}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict = {}\n",
    "for week, hashcodes_arr in enumerate(week_hashcodes):\n",
    "    for i in hashcodes_arr:\n",
    "        if i in count_dict:\n",
    "            count_dict[i]['occurance_week_' + str(week)] += 1\n",
    "        else:\n",
    "            count_dict[i] = {}\n",
    "            count_dict[i]['occurance_week_0'] = 0\n",
    "            count_dict[i]['occurance_week_1'] = 0\n",
    "            count_dict[i]['occurance_week_2'] = 0\n",
    "            count_dict[i]['occurance_week_' + str(week)] += 1\n",
    "\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'is_predicted_group_percentage': 95.0,\n",
      "     'is_relevant_group_percentage': 'unknown',\n",
      "     'occurance_week_0': 10,\n",
      "     'occurance_week_1': 30,\n",
      "     'occurance_week_2': 42},\n",
      " 5: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "     'is_relevant_group_percentage': 'unknown',\n",
      "     'occurance_week_0': 62,\n",
      "     'occurance_week_1': 122,\n",
      "     'occurance_week_2': 170},\n",
      " 6: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "     'is_relevant_group_percentage': 'unknown',\n",
      "     'occurance_week_0': 66,\n",
      "     'occurance_week_1': 118,\n",
      "     'occurance_week_2': 154},\n",
      " 7: {'is_predicted_group_percentage': 28.8,\n",
      "     'is_relevant_group_percentage': 'unknown',\n",
      "     'occurance_week_0': 4,\n",
      "     'occurance_week_1': 8,\n",
      "     'occurance_week_2': 12},\n",
      " 9: {'is_predicted_group_percentage': 95.0,\n",
      "     'is_relevant_group_percentage': 'unknown',\n",
      "     'occurance_week_0': 18,\n",
      "     'occurance_week_1': 42,\n",
      "     'occurance_week_2': 68},\n",
      " 10: {'is_predicted_group_percentage': 95.0,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 22,\n",
      "      'occurance_week_1': 36,\n",
      "      'occurance_week_2': 56},\n",
      " 11: {'is_predicted_group_percentage': 2.4,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 0,\n",
      "      'occurance_week_1': 0,\n",
      "      'occurance_week_2': 2},\n",
      " 12: {'is_predicted_group_percentage': 97.5,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 54,\n",
      "      'occurance_week_1': 84,\n",
      "      'occurance_week_2': 146},\n",
      " 13: {'is_predicted_group_percentage': 50.4,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 6,\n",
      "      'occurance_week_1': 12,\n",
      "      'occurance_week_2': 24},\n",
      " 14: {'is_predicted_group_percentage': 38.4,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 2,\n",
      "      'occurance_week_1': 12,\n",
      "      'occurance_week_2': 18},\n",
      " 15: {'is_predicted_group_percentage': 2.4,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 0,\n",
      "      'occurance_week_1': 0,\n",
      "      'occurance_week_2': 2},\n",
      " 17: {'is_predicted_group_percentage': 95.0,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 20,\n",
      "      'occurance_week_1': 36,\n",
      "      'occurance_week_2': 52},\n",
      " 18: {'is_predicted_group_percentage': 86.4,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 12,\n",
      "      'occurance_week_1': 24,\n",
      "      'occurance_week_2': 36},\n",
      " 19: {'is_predicted_group_percentage': 12.0,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 0,\n",
      "      'occurance_week_1': 4,\n",
      "      'occurance_week_2': 6},\n",
      " 20: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 68,\n",
      "      'occurance_week_1': 130,\n",
      "      'occurance_week_2': 184},\n",
      " 21: {'is_predicted_group_percentage': 64.8,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 8,\n",
      "      'occurance_week_1': 22,\n",
      "      'occurance_week_2': 24},\n",
      " 22: {'is_predicted_group_percentage': 57.6,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 10,\n",
      "      'occurance_week_1': 14,\n",
      "      'occurance_week_2': 24},\n",
      " 24: {'is_predicted_group_percentage': 95.0,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 14,\n",
      "      'occurance_week_1': 28,\n",
      "      'occurance_week_2': 46},\n",
      " 25: {'is_predicted_group_percentage': 24.0,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 4,\n",
      "      'occurance_week_1': 6,\n",
      "      'occurance_week_2': 10},\n",
      " 26: {'is_predicted_group_percentage': 19.2,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 4,\n",
      "      'occurance_week_1': 6,\n",
      "      'occurance_week_2': 6},\n",
      " 28: {'is_predicted_group_percentage': 43.2,\n",
      "      'is_relevant_group_percentage': 'unknown',\n",
      "      'occurance_week_0': 4,\n",
      "      'occurance_week_1': 12,\n",
      "      'occurance_week_2': 20}}\n"
     ]
    }
   ],
   "source": [
    "threshold = 75\n",
    "threshold_perc = 90\n",
    "for key,val in count_dict.items():\n",
    "    occurances_3_weeks = val['occurance_week_0'] + val['occurance_week_1'] + val['occurance_week_2']\n",
    "    if occurances_3_weeks >= threshold:\n",
    "        div = (occurances_3_weeks / threshold)\n",
    "        count = 0\n",
    "        perc = threshold_perc\n",
    "        while div > 1:\n",
    "            count += 1\n",
    "            div /= 2\n",
    "            perc += ((100 - threshold_perc) / 2) * (1 / count)\n",
    "            count_dict[key]['is_predicted_group_percentage'] = perc\n",
    "            \n",
    "    else:\n",
    "        count_dict[key]['is_predicted_group_percentage'] = round(\n",
    "            (occurances_3_weeks / threshold) * threshold_perc, 2\n",
    "        )\n",
    "\n",
    "        \n",
    "##### TODO: dat zeg ik, GAMMA!\n",
    "for key,val in count_dict.items():\n",
    "    count_dict[key]['is_relevant_group_percentage'] = 'unknown'\n",
    "##### TODO: dat zeg ik, GAMMA!\n",
    "\n",
    "pprint.pprint(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
