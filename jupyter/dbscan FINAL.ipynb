{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data visualisaton params for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 0.1\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '../datasets/staandelamp_realistic.json'\n",
    "df_data = pd.read_json(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the data on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>TEMP</font> Cut off the dataset (Grab around 6 hours of timestamps) <font color='red'>TEMP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1509489940655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Staande_Lamp_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1509490011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Staande_Lamp_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1509491943009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staande_Lamp_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1509492221471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staande_Lamp_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1509492826941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  state           time\n",
       "2  Staande_Lamp_3      0  1509489940655\n",
       "6  Staande_Lamp_5      1  1509490011225\n",
       "0  Staande_Lamp_1      1  1509491943009\n",
       "1  Staande_Lamp_2      0  1509492221471\n",
       "3  Staande_Lamp_3      1  1509492826941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_dataframe_for_fitting(df):\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    df_fit = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "    df_fit['state'] = df['state']\n",
    "    df_fit['time'] = df['time']\n",
    "    return df_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the DBSCAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_untill_its_a_cluster = 2\n",
    "\n",
    "def fit_model(df, eps_distance_in_milliseconds):\n",
    "    model = DBSCAN(\n",
    "        eps=eps_distance_in_milliseconds, \n",
    "        min_samples=min_samples_untill_its_a_cluster\n",
    "    ).fit(df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(model):\n",
    "    info_dict = {}\n",
    "    info_dict['amount_of_datapoints'] = model.labels_.size\n",
    "    info_dict['amount_of_outliers'] = Counter(model.labels_)[-1]\n",
    "    \n",
    "    \n",
    "    cluster_data_count = Counter(model.labels_)\n",
    "    if -1 in cluster_data_count:\n",
    "        cluster_data_count.pop(-1) # don't count outliers as a cluster\n",
    "    if (bool(cluster_data_count)):\n",
    "        amount_of_clusters = max(cluster_data_count) + 1\n",
    "    else:\n",
    "        amount_of_clusters = 0;\n",
    "    info_dict['amount_of_clusters'] = amount_of_clusters\n",
    "    info_dict['datapoints_per_cluster_dict'] = Counter(model.labels_)\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_on_cluster(model, df):\n",
    "    df['cluster'] = model.labels_\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    \n",
    "    amount_of_clusters = get_model_info(model)['amount_of_clusters']\n",
    "    \n",
    "    for idx in range(amount_of_clusters):\n",
    "        cluster_dict[idx] = df.loc[df['cluster'] == idx].drop(columns=['cluster'])\n",
    "\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_large_clusters(cluster_dict, limit_in_milliseconds):\n",
    "    too_large_clusters_dataframes_dict = {}\n",
    "\n",
    "    for idx, df in cluster_dict.items():\n",
    "\n",
    "        first_time = df['time'].iloc[0]\n",
    "        last_time = df['time'].iloc[df['time'].size - 1]\n",
    "\n",
    "        diffrence_in_miliseconds = last_time - first_time\n",
    "        # diffrence_in_minutes = diffrence_in_miliseconds / 1000 / 60\n",
    "\n",
    "        if diffrence_in_miliseconds > limit_in_milliseconds:\n",
    "            too_large_clusters_dataframes_dict[idx] = df\n",
    "\n",
    "    return too_large_clusters_dataframes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perfect_size_clusters(cluster_dict, limit_in_milliseconds):\n",
    "    perfect_size_clusters_dataframes_dict = {}\n",
    "\n",
    "    for idx, df in cluster_dict.items():\n",
    "\n",
    "        first_time = df['time'].iloc[0]\n",
    "        last_time = df['time'].iloc[df['time'].size - 1]\n",
    "\n",
    "        diffrence_in_miliseconds = last_time - first_time\n",
    "        # diffrence_in_minutes = diffrence_in_miliseconds / 1000 / 60\n",
    "\n",
    "        if diffrence_in_miliseconds <= limit_in_milliseconds:\n",
    "            perfect_size_clusters_dataframes_dict[idx] = df\n",
    "\n",
    "    return perfect_size_clusters_dataframes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (300000 milliseconds = 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def do_shit(df, eps, iteration=0, cluster_arr=[]):\n",
    "    \n",
    "    model = fit_model(df, eps)\n",
    "    cluster_dict = split_dataframe_on_cluster(model, df)\n",
    "    \n",
    "    too_large_clusters_dict = get_too_large_clusters(cluster_dict, eps * 1.5)\n",
    "    perfect_size_clusters = get_perfect_size_clusters(cluster_dict, eps * 1.5)\n",
    "    \n",
    "    for idx, df in too_large_clusters_dict.items():\n",
    "        cluster_arr + do_shit(too_large_clusters_dict[idx], eps / 2, iteration + 1, cluster_arr)\n",
    "    \n",
    "    for idx, df in perfect_size_clusters.items():\n",
    "        cluster_arr.append(df)\n",
    "    \n",
    "    return cluster_arr\n",
    "\n",
    "\n",
    "\n",
    "five_minutes = 300000\n",
    "\n",
    "one_week_in_milliseconds = (1000 * 60 * 60 * 24 * 7)\n",
    "last_timestamp = df_data['time'].max()\n",
    "\n",
    "weeks_clusters = []\n",
    "for week in range(3):\n",
    "    df_week_x = df_data[df_data['time'] >= last_timestamp - ((week + 1) * one_week_in_milliseconds)]\n",
    "    df_week_x = df_week_x[df_week_x['time'] < last_timestamp - (week * one_week_in_milliseconds)]\n",
    "    df_fit_1 = clean_dataframe_for_fitting(df_week_x.loc[df_week_x['state'] == 1])\n",
    "    df_fit_0 = clean_dataframe_for_fitting(df_week_x.loc[df_week_x['state'] == 0])\n",
    "    cluster_arr1 = do_shit(df_fit_1, five_minutes)\n",
    "    cluster_arr2 = do_shit(df_fit_0, five_minutes)\n",
    "    cluster_arr = cluster_arr1 + cluster_arr2\n",
    "    weeks_clusters.append(cluster_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "2236\n",
      "[20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20, 20, 17, 5, 25, 6, 18, 6, 6, 6, 20, 12, 18, 6, 5, 20, 12, 18, 10, 12, 6, 24, 14, 22, 20, 5, 6, 5, 20, 9, 6, 21, 6, 20, 5, 5, 24, 6, 6, 5, 17, 6, 12, 5, 13, 12, 9, 22, 24, 20, 21, 17, 5, 10, 5, 10, 5, 20, 3, 10, 9, 6, 6, 12, 24, 10, 20, 10, 5, 20, 12, 5, 12, 20, 17, 6, 6, 12, 21, 13, 17, 12, 17, 7, 6, 12, 5, 6, 3, 20, 6, 17, 5, 5, 6, 9, 24, 6, 5, 12, 20, 5, 12, 10, 20, 18, 20, 13, 12, 6, 12, 5, 12, 20, 10, 20, 5, 12, 12, 20, 5, 17, 10, 25, 26, 17, 5, 10, 20, 21, 5, 6, 12, 5, 20, 22, 6, 5, 20, 6, 12, 9, 17, 6, 5, 6, 26, 20, 3, 6, 12, 28, 6, 9, 12, 10, 20, 5, 18, 12, 20, 24, 20, 20, 20, 6, 20, 28, 5, 5, 9, 9, 18, 22, 6, 20, 20, 5, 24, 22, 9, 6, 12, 7, 20, 12, 12, 5, 3, 20, 6, 12, 3, 20, 20]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "hashcodes_3_weeks = []\n",
    "hashcodes_last_week = []\n",
    "for week, cluster_arr in enumerate(weeks_clusters):\n",
    "    for idx, df in enumerate(cluster_arr):\n",
    "        cluster = []\n",
    "        for row in df.iterrows():\n",
    "            index, data = row\n",
    "            cluster.append(data['name'].tolist())\n",
    "\n",
    "        cluster = list(set(cluster))\n",
    "\n",
    "        hashcodedingus = 0\n",
    "        for lamp in cluster:\n",
    "            hashcodedingus += pow(2, lamp)\n",
    "\n",
    "        if(len(cluster) > 1):\n",
    "            hashcodes_3_weeks.append(hashcodedingus)\n",
    "            if week == 0:\n",
    "                hashcodes_last_week.append(hashcodedingus)\n",
    "    \n",
    "print(len(hashcodes_last_week))\n",
    "print(len(hashcodes_3_weeks))\n",
    "print(hashcodes_last_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: {'occurance_last_3_weeks': 382, 'occurance_last_week': 68},\n",
       " 17: {'occurance_last_3_weeks': 108, 'occurance_last_week': 20},\n",
       " 5: {'occurance_last_3_weeks': 354, 'occurance_last_week': 62},\n",
       " 25: {'occurance_last_3_weeks': 20, 'occurance_last_week': 4},\n",
       " 6: {'occurance_last_3_weeks': 338, 'occurance_last_week': 66},\n",
       " 18: {'occurance_last_3_weeks': 72, 'occurance_last_week': 12},\n",
       " 12: {'occurance_last_3_weeks': 284, 'occurance_last_week': 54},\n",
       " 10: {'occurance_last_3_weeks': 114, 'occurance_last_week': 22},\n",
       " 24: {'occurance_last_3_weeks': 88, 'occurance_last_week': 14},\n",
       " 14: {'occurance_last_3_weeks': 32, 'occurance_last_week': 2},\n",
       " 22: {'occurance_last_3_weeks': 48, 'occurance_last_week': 10},\n",
       " 9: {'occurance_last_3_weeks': 128, 'occurance_last_week': 18},\n",
       " 21: {'occurance_last_3_weeks': 54, 'occurance_last_week': 8},\n",
       " 13: {'occurance_last_3_weeks': 42, 'occurance_last_week': 6},\n",
       " 3: {'occurance_last_3_weeks': 82, 'occurance_last_week': 10},\n",
       " 7: {'occurance_last_3_weeks': 24, 'occurance_last_week': 4},\n",
       " 26: {'occurance_last_3_weeks': 16, 'occurance_last_week': 4},\n",
       " 28: {'occurance_last_3_weeks': 36, 'occurance_last_week': 4},\n",
       " 19: {'occurance_last_3_weeks': 10, 'occurance_last_week': 0},\n",
       " 15: {'occurance_last_3_weeks': 2, 'occurance_last_week': 0},\n",
       " 11: {'occurance_last_3_weeks': 2, 'occurance_last_week': 0}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict = {}\n",
    "for i in hashcodes_3_weeks:\n",
    "    if i in count_dict:\n",
    "        count_dict[i]['occurance_last_3_weeks'] += 1\n",
    "    else:\n",
    "        count_dict[i] = {}\n",
    "        count_dict[i]['occurance_last_3_weeks'] = 1\n",
    "        count_dict[i]['occurance_last_week'] = 0\n",
    "\n",
    "for i in hashcodes_last_week:\n",
    "    count_dict[i]['occurance_last_week'] += 1\n",
    "\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "{3: {'is_predicted_group_percentage': 95.0,\n",
      "     'occurance_last_3_weeks': 82,\n",
      "     'occurance_last_week': 10},\n",
      " 5: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "     'occurance_last_3_weeks': 354,\n",
      "     'occurance_last_week': 62},\n",
      " 6: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "     'occurance_last_3_weeks': 338,\n",
      "     'occurance_last_week': 66},\n",
      " 7: {'is_predicted_group_percentage': 28.8,\n",
      "     'occurance_last_3_weeks': 24,\n",
      "     'occurance_last_week': 4},\n",
      " 9: {'is_predicted_group_percentage': 95.0,\n",
      "     'occurance_last_3_weeks': 128,\n",
      "     'occurance_last_week': 18},\n",
      " 10: {'is_predicted_group_percentage': 95.0,\n",
      "      'occurance_last_3_weeks': 114,\n",
      "      'occurance_last_week': 22},\n",
      " 11: {'is_predicted_group_percentage': 2.4,\n",
      "      'occurance_last_3_weeks': 2,\n",
      "      'occurance_last_week': 0},\n",
      " 12: {'is_predicted_group_percentage': 97.5,\n",
      "      'occurance_last_3_weeks': 284,\n",
      "      'occurance_last_week': 54},\n",
      " 13: {'is_predicted_group_percentage': 50.4,\n",
      "      'occurance_last_3_weeks': 42,\n",
      "      'occurance_last_week': 6},\n",
      " 14: {'is_predicted_group_percentage': 38.4,\n",
      "      'occurance_last_3_weeks': 32,\n",
      "      'occurance_last_week': 2},\n",
      " 15: {'is_predicted_group_percentage': 2.4,\n",
      "      'occurance_last_3_weeks': 2,\n",
      "      'occurance_last_week': 0},\n",
      " 17: {'is_predicted_group_percentage': 95.0,\n",
      "      'occurance_last_3_weeks': 108,\n",
      "      'occurance_last_week': 20},\n",
      " 18: {'is_predicted_group_percentage': 86.4,\n",
      "      'occurance_last_3_weeks': 72,\n",
      "      'occurance_last_week': 12},\n",
      " 19: {'is_predicted_group_percentage': 12.0,\n",
      "      'occurance_last_3_weeks': 10,\n",
      "      'occurance_last_week': 0},\n",
      " 20: {'is_predicted_group_percentage': 99.16666666666667,\n",
      "      'occurance_last_3_weeks': 382,\n",
      "      'occurance_last_week': 68},\n",
      " 21: {'is_predicted_group_percentage': 64.8,\n",
      "      'occurance_last_3_weeks': 54,\n",
      "      'occurance_last_week': 8},\n",
      " 22: {'is_predicted_group_percentage': 57.6,\n",
      "      'occurance_last_3_weeks': 48,\n",
      "      'occurance_last_week': 10},\n",
      " 24: {'is_predicted_group_percentage': 95.0,\n",
      "      'occurance_last_3_weeks': 88,\n",
      "      'occurance_last_week': 14},\n",
      " 25: {'is_predicted_group_percentage': 24.0,\n",
      "      'occurance_last_3_weeks': 20,\n",
      "      'occurance_last_week': 4},\n",
      " 26: {'is_predicted_group_percentage': 19.2,\n",
      "      'occurance_last_3_weeks': 16,\n",
      "      'occurance_last_week': 4},\n",
      " 28: {'is_predicted_group_percentage': 43.2,\n",
      "      'occurance_last_3_weeks': 36,\n",
      "      'occurance_last_week': 4}}\n"
     ]
    }
   ],
   "source": [
    "threshold = 75\n",
    "threshold_perc = 90\n",
    "for key,val in count_dict.items():\n",
    "    if val['occurance_last_3_weeks'] >= threshold:\n",
    "        div = (count_dict[key]['occurance_last_3_weeks'] / threshold)\n",
    "        count = 0\n",
    "        perc = threshold_perc\n",
    "        while div > 1:\n",
    "            count += 1\n",
    "            div /= 2\n",
    "            perc += 5 * (1 / count)\n",
    "            count_dict[key]['is_predicted_group_percentage'] = perc\n",
    "            \n",
    "    else:\n",
    "        count_dict[key]['is_predicted_group_percentage'] = round(\n",
    "            (count_dict[key]['occurance_last_3_weeks'] / threshold) * threshold_perc, 2\n",
    "        )\n",
    "\n",
    "for key,val in count_dict.items():\n",
    "    if val['occurance_last_week'] >= threshold / 3:\n",
    "        print('lol')\n",
    "    else:\n",
    "        print('lol')\n",
    "        \n",
    "pprint.pprint(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
